Quality Gateway
 Revise requirements **before** they make it to the **official list** (?)
 Revise **individual** requirements
 Apply quality gateway tests to requirements **during** their creation

Requirements quality
 Doesn't always have to be a **document**
 "Specification": Collection of requirements held in **whatever manner**
 
Quality gateway: **filter** of bad requirements
 Bad requirements: out of scope, incomplete, untraceable, inconsistent, irrelevant, incorrect, ambiguous, non-viable, solution-bound, gold-plated
 Accepted requirements are stored in the **specification**

Out of scope requirements
 Generated by over-enthusiasm of the project
 Check the relevancy of the requirement
  Compare the requirement with the project goals
  When considering relevancy, pay attention to:
   stakeholders >> users
   requirements >> constraints
   Relevant facts & assumptions

Testing **completeness**
 Using **snow cards** for it
  Check if all **atributes** are present
 Check if meaningful to **stakeholders**
  Watch out for **ambiguity**

Testing the **fit criterion**
 Check if it's **correctly defined**
 Check if usable as input for **acceptance test** design
 Check if **cost-effectively** testable
 Check if meets the **purpose**

Consistent terminology
 Avoid **ambiguity**
 **Define** terms and their meanings in the context of the specification

Viable within constraints?
 Viable: possible to develop and implement a solution cost-effectively and successfully
 Check if the organization is **mature** enough to cope with a req.
 Check if the req. can be built with the **skills** of the dev. team
 Check if time, money and other **resources** are sufficient
 Check if req. is **acceptable** within stakeholders
 Check other **constraints** that make the req. non-viable

Requirement or solution?
 Req. must not provide details about solution
  Aside the fundamental

Requirement value
 Reward, punishment (for not implementing), and cost
 R >= C & P >= C ==> Prioritize
 R < C XOR P < C ==> Evaluate
 R < C & P < C ==> Discard

Gold plating
 Filter **fancy** but useless requirements
 **Check if it matters** whether the req. is included
 Check if customer **dissatisfaction** is low for it

Requirements creep
 Adding **new reqs** after the specification is complete
 Quality gateway participates in controlling it
 If **satisfaction** is high, it can be tolerated
 The req must be **inside the scope**
 The **rationale** must make sense
 Causes:
  Req. incompleteness
  Lack of participation from users
  Too low budget

Implementing QG
 Questions:
  Who will take care of it?
   One person?
    Who?
   Several people?
    Are they only testers and req analysts?
   Is the project leader included?
   Is the client represented?
  How formal must be?
  Should inspection reports be issued?
  Prearrange QG inspection meetings?
 Suggestions:
  Start with two people (lead req analyst and a tester)
  In most cases, it can be informal, unless necessary
 Alternatives:
  Buddy pairing
  Four-stage process for elephants:
   1. Each developer has a checklist used to review and improve reqs during the dev process
   2. Peer review, preferably from someone from the test team, results are recorded in the history of the req
   3. Team review, rejected reqs are discussed
   4. Management review, checking summary of successes and failures, results are used as feedback to fine-tune reqs
 QG must be **fast and easy**

Summary:
 QG tests whether reqs follow these criteria:
  Completeness
  Traceability
  Consistency
  Relevancy
  Correctness
  Non-ambiguity
  Viability
  Being solution-bound
  Gold plating
  Creep